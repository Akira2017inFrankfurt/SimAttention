{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60b22188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbde3053",
   "metadata": {},
   "source": [
    "### FPS方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5ed5ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def farthest_point_sample(xyz, npoint): \n",
    "\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        xyz: pointcloud data, [B, N, 3]\n",
    "        npoint: number of samples\n",
    "    Return:\n",
    "        result: sampled pointcloud , [B, npoint, 3]\n",
    "    \"\"\"\n",
    "    \n",
    "    device = xyz.device\n",
    "    B, N, C = xyz.shape\n",
    "    result = torch.zeros(B, npoint, C).to(device)\n",
    "    \n",
    "    centroids = torch.zeros(B, npoint, dtype=torch.long).to(device)     \n",
    "    distance = torch.ones(B, N).to(device) * 1e10                       \n",
    "\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(device)        \n",
    "    \n",
    "    barycenter = torch.sum((xyz), 1)                                    \n",
    "    barycenter = barycenter/xyz.shape[1]\n",
    "    barycenter = barycenter.view(B, 1, 3)\n",
    "\n",
    "    dist = torch.sum((xyz - barycenter) ** 2, -1)\n",
    "    farthest = torch.max(dist,1)[1]                                     \n",
    "\n",
    "    for i in range(npoint):\n",
    "        centroids[:, i] = farthest                                      \n",
    "        centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)        \n",
    "        dist = torch.sum((xyz - centroid) ** 2, -1)                     \n",
    "        mask = dist < distance\n",
    "        distance[mask] = dist[mask]                                     \n",
    "        farthest = torch.max(distance, -1)[1]                           \n",
    "    \n",
    "    for b in range(0, B):\n",
    "        for index in range(0, npoint):\n",
    "            # todo 后面是不是可以改成生成式的形式？\n",
    "            result[b, index] = xyz[b, centroids[b, index]]\n",
    "    \n",
    "    # r = [xyz[b, centroids[b, i]].item() for b in range(0, B) for i in range(0, npoint)]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a27c9323",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9679, 0.3245, 0.2039],\n",
       "         [0.0267, 0.4265, 0.7912],\n",
       "         [0.2179, 0.8170, 0.0824],\n",
       "         [0.4956, 0.9449, 0.9740]],\n",
       "\n",
       "        [[0.9840, 0.6193, 0.0824],\n",
       "         [0.3369, 0.8668, 0.9643],\n",
       "         [0.2591, 0.0509, 0.2863],\n",
       "         [0.5662, 0.3188, 0.8705]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = farthest_point_sample(sim_data, 4)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ad72f444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a492d8",
   "metadata": {},
   "source": [
    "### Slice方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651830a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slice(point_set, xyz_dim, index_slice, npoints):\n",
    "    device = point_set.device\n",
    "    B, _, C = point_set.shape\n",
    "    result = torch.zeros((B, npoints, C)).to(device)\n",
    "    \n",
    "    def get_slice_index(index_slice, ratio_per_slice, overlap_ratio, num_all_points):\n",
    "        start_index = index_slice * (ratio_per_slice - overlap_ratio) * num_all_points\n",
    "        end_index = start_index + ratio_per_slice * num_all_points\n",
    "        return int(start_index), int(end_index)\n",
    "\n",
    "    def get_1_slice(point_set, xyz_dim, index_slice, npoints):\n",
    "        # xyz_dim: 0, 1, 2 for x, y, z\n",
    "        start_index, end_index = get_slice_index(index_slice, 0.4, 0.1, len(point_set))\n",
    "        patch_index = torch.argsort(point_set, dim=0)[start_index: end_index, xyz_dim]\n",
    "        patch = point_set[patch_index]\n",
    "        random.shuffle(patch)\n",
    "        if len(patch_index) > npoints:\n",
    "            patch = fps(patch, npoints)\n",
    "        return patch\n",
    "\n",
    "    for b in range(0, B):\n",
    "        result[b] = get_1_slice(point_set[b], xyz_dim, index_slice, npoints)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15060bb",
   "metadata": {},
   "source": [
    "### Slice 测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40ca57d",
   "metadata": {},
   "source": [
    "### Cube方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ff6f8754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cube(point_set, side_length, npoints):\n",
    "    device = point_set.device\n",
    "    B, _, C = point_set.shape\n",
    "    result = torch.zeros((B, npoints, C)).to(device)\n",
    "\n",
    "    def point_in_cube(point_xyz, side_length):\n",
    "        flag = True\n",
    "        for i in range(0, len(point_xyz)):\n",
    "            if abs(point_xyz[i]) >= (side_length / 2):\n",
    "                flag = False\n",
    "                break\n",
    "        return flag\n",
    "\n",
    "    def get_1_cube(point_set, side_length, npoints):\n",
    "        sample_index = []\n",
    "        for i in range(0, len(point_set)):\n",
    "            if point_in_cube(point_set[i], side_length):\n",
    "                sample_index.append(i)\n",
    "        if len(sample_index) >= npoints:\n",
    "            r = fps(point_set[sample_index], npoints)\n",
    "            return r\n",
    "        else:\n",
    "            return get_1_cube(point_set, side_length + 0.1, npoints)\n",
    "\n",
    "    for i in range(point_set.shape[0]):\n",
    "        result[i] = get_1_cube(point_set[i], side_length, npoints)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6a756d",
   "metadata": {},
   "source": [
    "### Cube方法测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a96ad60",
   "metadata": {},
   "source": [
    "### Sphere方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371df1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sphere(point_set, radius, npoints):\n",
    "    device = point_set.device\n",
    "    B, _, C = point_set.shape\n",
    "    result = torch.zeros((B, npoints, C)).to(device)\n",
    "\n",
    "    def point_in_ball(point_xyz, center_xyz, radius):\n",
    "        flag = False\n",
    "        dist = 0\n",
    "        for i in range(3):\n",
    "            dist += (point_xyz[i] - center_xyz[i]) ** 2\n",
    "        if dist <= radius ** 2:\n",
    "            flag = True\n",
    "        return flag\n",
    "\n",
    "    def get_1_sphere(point_set, radius, npoints):\n",
    "        center_xyz = torch.zeros([1, 3])\n",
    "        sample_index = []\n",
    "        for i in range(0, len(point_set)):\n",
    "            if point_in_ball(point_set[i], center_xyz, radius):\n",
    "                sample_index.append(i)\n",
    "        if len(sample_index) >= npoints:\n",
    "            r = fps(point_set[sample_index], npoints)\n",
    "            return r\n",
    "        else:\n",
    "            return get_1_sphere(point_set, radius + 0.1, npoints)\n",
    "\n",
    "    for i in range(point_set.shape[0]):\n",
    "        result[i] = get_1_sphere(point_set[i], radius, npoints)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "931e0c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.random()\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c133d079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_idx = np.where(np.random.random(20) <= 0.875)[0]\n",
    "type(drop_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2a1b512b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = np.random.uniform(-1,0,10)\n",
    "type(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a05b2565",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.91935565, -0.10548497, -0.00923473, -0.33601561, -0.34504973,\n",
       "       -0.99699527, -0.522479  , -0.23381304, -0.37536566, -0.00571747])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b11cdfd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9194, -0.1055, -0.0092, -0.3360, -0.3450, -0.9970, -0.5225, -0.2338,\n",
       "        -0.3754, -0.0057], dtype=torch.float64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = torch.from_numpy(s)\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f2c054f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1000, 3])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_point_set = torch.ones((4, 1000, 3))\n",
    "rand_point_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a8546d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_point_dropout(batch_pc, max_dropout_ratio=0.875):\n",
    "    device = batch_pc.device\n",
    "    # batch_pc: BxNx3\n",
    "    for b in range(batch_pc.shape[0]):\n",
    "        dropout_ratio = np.random.random()*max_dropout_ratio  # 0~0.875\n",
    "        drop_idx = np.where(np.random.random((batch_pc.shape[1])) <= dropout_ratio)[0]\n",
    "        drop_idx = torch.from_numpy(drop_idx).to(device)\n",
    "        r = batch_pc.clone()\n",
    "        if len(drop_idx) > 0:\n",
    "            r[b, drop_idx, :] = batch_pc[b, 0, :]  # set to the first point\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "43ca8a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1000, 3])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o1 = random_point_dropout(rand_point_set)\n",
    "o1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "55bc1a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_scale_point_cloud(batch_data, scale_low=0.8, scale_high=1.25):\n",
    "    \"\"\" Randomly scale the point cloud. Scale is per point cloud.\n",
    "        Input:\n",
    "            BxNx3 array, original batch of point clouds\n",
    "        Return:\n",
    "            BxNx3 array, scaled batch of point clouds\n",
    "    \"\"\"\n",
    "    B, N, C = batch_data.shape\n",
    "    device = batch_data.device\n",
    "    scales = np.random.uniform(scale_low, scale_high, B)\n",
    "    scales = torch.from_numpy(scales).to(device)\n",
    "    for batch_index in range(B):\n",
    "        batch_data[batch_index, :, :] *= scales[batch_index]\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "14ca9132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1000, 3])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o2 = random_scale_point_cloud(rand_point_set)\n",
    "o2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9247a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_point_cloud(batch_data, shift_range=0.1):\n",
    "    \"\"\" Randomly shift point cloud. Shift is per point cloud.\n",
    "        Input:\n",
    "          BxNx3 array, original batch of point clouds\n",
    "        Return:\n",
    "          BxNx3 array, shifted batch of point clouds\n",
    "    \"\"\"\n",
    "    B, N, C = batch_data.shape\n",
    "    device = batch_data.device\n",
    "    shifts = np.random.uniform(-shift_range, shift_range, (B, 3))\n",
    "    shifts = torch.from_numpy(shifts).to(device)\n",
    "    for batch_index in range(B):\n",
    "        batch_data[batch_index, :, :] += shifts[batch_index, :]\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d8d94bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1000, 3])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o3 = shift_point_cloud(rand_point_set)\n",
    "o3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2c4950",
   "metadata": {},
   "source": [
    "### Model 修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776be103",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimAttention_5(nn.Module):\n",
    "    def __init__(self,\n",
    "                 aug_function,\n",
    "                 sub_function,\n",
    "                 slice_function,\n",
    "                 cube_function,\n",
    "                 sphere_function,\n",
    "                 online_encoder,\n",
    "                 crossed_attention_method):\n",
    "        super().__init__()\n",
    "        self.aug_function = aug_function\n",
    "        self.sub_function = sub_function\n",
    "        self.slice_function = slice_function\n",
    "        self.cube_function = cube_function\n",
    "        self.sphere_function = sphere_function\n",
    "        self.online_encoder = online_encoder\n",
    "        self.target_encoder = None\n",
    "\n",
    "        self.crossed_attention = crossed_attention_method\n",
    "\n",
    "    def forward(self, x):\n",
    "        aug1, aug2 = self.aug_function(x), self.aug_function(x)\n",
    "        sub1, sub2 = self.sub_function(aug1, 1024), self.sub_function(aug2, 1024)\n",
    "        slice1, slice2 = self.slice_function(aug1, 1, 1, 1024), self.slice_function(aug2, 1, 1, 1024)\n",
    "        cube1, cube2 = self.cube_function(aug1, 0.2, 1024), self.cube_function(aug2, 0.2, 1024)\n",
    "        sphere1, sphere2 = self.sphere_function(aug1, 0.2, 1024), self.sphere_function(aug2, 0.1, 1024)\n",
    "\n",
    "        # [B, 1, N_f] N_f: output dimension of mlp: 512\n",
    "        sub_feature_1 = self.online_encoder(sub1)\n",
    "        sub_feature_3 = self.online_encoder(sub2)\n",
    "\n",
    "        # with momentum encoder\n",
    "        with torch.no_grad():\n",
    "            if self.target_encoder is None:\n",
    "                self.target_encoder = copy.deepcopy(self.online_encoder)\n",
    "            else:\n",
    "                for online_params, target_params in zip(self.online_encoder.parameters(),\n",
    "                                                        self.target_encoder.parameters()):\n",
    "                    target_weight, online_weight = target_params.data, online_params.data\n",
    "                    # moving average decay is tao\n",
    "                    tao = 0.99\n",
    "                    target_params.data = target_weight * tao + (1 - tao) * online_weight\n",
    "            for parameter in self.target_encoder.parameters():\n",
    "                parameter.requires_grad = False\n",
    "            sub_feature_2 = self.target_encoder(sub2)\n",
    "            sub_feature_4 = self.target_encoder(sub1)\n",
    "\n",
    "        # slice feature [B, 1, N_f]\n",
    "        slice_feature_1 = self.online_encoder(slice1)\n",
    "        slice_feature_2 = self.online_encoder(slice2)\n",
    "\n",
    "        # cube feature  [B, 1, N_f]\n",
    "        cube_feature_1 = self.online_encoder(cube1)\n",
    "        cube_feature_2 = self.online_encoder(cube2)\n",
    "\n",
    "        # sphere feature [B, 1, N_f]\n",
    "        sphere_feature_1 = self.online_encoder(sphere1)\n",
    "        sphere_feature_2 = self.online_encoder(sphere2)\n",
    "\n",
    "        # crop feature concat [B, 3, N_f]\n",
    "        crop_feature_1 = torch.cat((slice_feature_1, cube_feature_1, sphere_feature_1), dim=1)\n",
    "        crop_feature_2 = torch.cat((slice_feature_2, cube_feature_2, sphere_feature_2), dim=1)\n",
    "        # [B, 6, N_f]\n",
    "        crop_feature = torch.cat((crop_feature_1, crop_feature_2), dim=1)\n",
    "\n",
    "        # attention feature\n",
    "        attn_feature_1 = self.crossed_attention(sub_feature_1, crop_feature)\n",
    "        attn_feature_2 = self.crossed_attention(sub_feature_2, crop_feature)\n",
    "        attn_feature_3 = self.crossed_attention(sub_feature_3, crop_feature)\n",
    "        attn_feature_4 = self.crossed_attention(sub_feature_4, crop_feature)\n",
    "\n",
    "        # loss\n",
    "        loss_1 = loss_fn(attn_feature_1, attn_feature_2)\n",
    "        loss_2 = loss_fn(attn_feature_3, attn_feature_4)\n",
    "        loss = loss_1 + loss_2\n",
    "\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad6bc0a",
   "metadata": {},
   "source": [
    "### PointWOLF 部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a15284",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointWOLF(object):\n",
    "    # todo2: delete args\n",
    "    def __init__(self, w_sigma):\n",
    "        self.num_anchor = 4\n",
    "        self.sample_type = 'fps'  # 'random'\n",
    "        self.sigma = w_sigma\n",
    "\n",
    "        self.R_range = (-abs(10), abs(10))\n",
    "        self.S_range = (1., 3)\n",
    "        self.T_range = (-abs(0.25), abs(0.25))\n",
    "\n",
    "    def __call__(self, pos):\n",
    "        \"\"\"\n",
    "        input :\n",
    "            pos([N,3])\n",
    "\n",
    "        output :\n",
    "            pos([N,3]) : original pointcloud\n",
    "            pos_new([N,3]) : Pointcloud augmneted by PointWOLF\n",
    "        \"\"\"\n",
    "        device = pos.device\n",
    "        pos = pos.cpu().numpy()\n",
    "        M = self.num_anchor  # (Mx3)\n",
    "        N, _ = pos.shape  # (N)\n",
    "\n",
    "        if self.sample_type == 'random':\n",
    "            idx = np.random.choice(N, M)  # (M)\n",
    "        elif self.sample_type == 'fps':\n",
    "            idx = self.fps(pos, M)  # (M)\n",
    "\n",
    "        pos_anchor = pos[idx]  # (M,3), anchor point\n",
    "        pos_repeat = np.expand_dims(pos, 0).repeat(M, axis=0)  # (M,N,3)\n",
    "        pos_normalize = np.zeros_like(pos_repeat, dtype=pos.dtype)  # (M,N,3)\n",
    "        pos_normalize = pos_repeat - pos_anchor.reshape(M, -1, 3)\n",
    "\n",
    "        # Local transformation at anchor point\n",
    "        pos_transformed = self.local_transformaton(pos_normalize)  # (M,N,3)\n",
    "\n",
    "        # Move to origin space\n",
    "        pos_transformed = pos_transformed + pos_anchor.reshape(M, -1, 3)  # (M,N,3)\n",
    "\n",
    "        pos_new = self.kernel_regression(pos, pos_anchor, pos_transformed)\n",
    "        pos_new = self.normalize(pos_new)\n",
    "        result = torch.from_numpy(pos_new.astype('float32')).to(device)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5a21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6075e46d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
